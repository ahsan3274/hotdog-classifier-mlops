{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7075286",
   "metadata": {},
   "source": [
    "# üì¶ MobileNetV2 Training + MLflow Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af713fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import mlflow.pyfunc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "446dbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"data\"  # expects data/train and data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8383043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce04f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "for param in base_model.features.parameters():\n",
    "    param.requires_grad = False  # optional: freeze feature extractor\n",
    "\n",
    "base_model.classifier[1] = nn.Linear(base_model.last_channel, NUM_CLASSES)\n",
    "base_model = base_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4531e7fa-6c09-41fe-8251-edab116ee885",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_model.parameters(), lr=1e-3)\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7ccfc28-60d3-49f6-9314-53a6d773c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.3017, Val Acc: 0.7780\n",
      "Epoch 2/10, Train Loss: 0.3220, Val Acc: 0.7780\n",
      "Epoch 3/10, Train Loss: 0.3461, Val Acc: 0.7660\n",
      "Epoch 4/10, Train Loss: 0.2974, Val Acc: 0.7960\n",
      "Epoch 5/10, Train Loss: 0.2725, Val Acc: 0.7640\n",
      "Epoch 6/10, Train Loss: 0.3007, Val Acc: 0.8080\n",
      "Epoch 7/10, Train Loss: 0.2619, Val Acc: 0.7980\n",
      "Epoch 8/10, Train Loss: 0.3101, Val Acc: 0.7720\n",
      "Epoch 9/10, Train Loss: 0.3069, Val Acc: 0.8100\n",
      "Epoch 10/10, Train Loss: 0.2524, Val Acc: 0.8080\n",
      "‚úÖ Torch model state_dict saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahsan\\onedrive\\documents\\mlops\\hotdog-classifier\\venv\\lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "C:\\Users\\ahsan\\onedrive\\documents\\mlops\\hotdog-classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ahsan\\onedrive\\documents\\mlops\\hotdog-classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "2025/06/16 03:00:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model logged to MLflow with pyfunc wrapper.\n",
      "üèÉ View run traveling-fox-18 at: http://127.0.0.1:5000/#/experiments/910632922734708419/runs/25bf3a3031e145eb855e8f90c1fe0b99\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/910632922734708419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahsan\\onedrive\\documents\\mlops\\hotdog-classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ahsan\\onedrive\\documents\\mlops\\hotdog-classifier\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction with float32: [1]\n",
      "Prediction with float64: [1]\n",
      "Prediction with single image (float64): [1]\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"hotdog-classifier-mobilenet-v2\")\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param(\"model\", \"MobileNetV2\")\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        base_model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = base_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        val_acc = evaluate(base_model, test_loader)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_val_acc = evaluate(base_model, test_loader)\n",
    "    mlflow.log_metric(\"final_val_accuracy\", final_val_acc)\n",
    "    \n",
    "    # Save the trained model state_dict\n",
    "    torch.save(base_model.state_dict(), \"mobilenetv2_state.pt\")\n",
    "    print(\"‚úÖ Torch model state_dict saved.\")\n",
    "\n",
    "    # Log the .pt file as an MLflow artifact, and also log using Pyfunc\n",
    "    class MobileNetV2MLflowWrapper(mlflow.pyfunc.PythonModel):\n",
    "        def load_context(self, context):\n",
    "            import torch\n",
    "            import torchvision\n",
    "            import torch.nn as nn\n",
    "            # Rebuild the model and load the state_dict\n",
    "            model = torchvision.models.mobilenet_v2(pretrained=False)\n",
    "            model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
    "            state_dict = torch.load(context.artifacts[\"torch_model_state\"], map_location=\"cpu\")\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.eval()\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(self.device)\n",
    "            self.model = model\n",
    "\n",
    "        def predict(self, context, model_input):\n",
    "            import torch\n",
    "            # Accept both numpy arrays and DataFrames\n",
    "            if hasattr(model_input, \"values\"):\n",
    "                x = model_input.values\n",
    "            else:\n",
    "                x = model_input\n",
    "            # Ensure float32 and torch tensor\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "            # Add batch dimension if single image\n",
    "            if x.ndim == 3:\n",
    "                x = x.unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(x)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "            return preds.cpu().numpy()\n",
    "\n",
    "    artifacts = {\"torch_model_state\": \"mobilenetv2_state.pt\"}\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=MobileNetV2MLflowWrapper(),\n",
    "        artifacts=artifacts,\n",
    "    )\n",
    "    print(\"‚úÖ Model logged to MLflow with pyfunc wrapper.\")\n",
    "\n",
    "# Cell 8: Local Inference Test (float32 and float64)\n",
    "run_id = run.info.run_id\n",
    "pyfunc_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")\n",
    "\n",
    "# Generate a dummy image, with proper normalization and shape (batch, channels, H, W)\n",
    "dummy_img_float32 = np.random.randn(1, 3, 128, 128).astype(np.float32)\n",
    "dummy_img_float64 = np.random.randn(1, 3, 128, 128).astype(np.float64)\n",
    "\n",
    "print(\"Prediction with float32:\", pyfunc_model.predict(dummy_img_float32))\n",
    "print(\"Prediction with float64:\", pyfunc_model.predict(dummy_img_float64))  # Should work!\n",
    "\n",
    "# You can also test with a single image shape (3, 128, 128):\n",
    "single_img = np.random.randn(3, 128, 128).astype(np.float64)\n",
    "print(\"Prediction with single image (float64):\", pyfunc_model.predict(single_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfaa741-4be1-471b-b3d4-eebf475c7d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hotdog-venv)",
   "language": "python",
   "name": "hotdog-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
